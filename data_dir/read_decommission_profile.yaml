#
# This is an example YAML profile for cassandra-stress
#
# insert data
# ./tools/bin/cassandra-stress user profile=/home/raphaelsc/scylla-tools-java/tools/my_cqlstress-example.yaml ops\(insert=1\) duration=30m -pop seq=1..1000000000 -mode native cql3 -rate threads=100 -node 127.0.0.1
#
# read, using query simple1:
# ./tools/bin/cassandra-stress user profile=/home/raphaelsc/scylla-tools-java/tools/my_cqlstress-example.yaml ops\(simple1=1\) duration=30m -mode native cql3 -rate threads=100 -node 127.0.0.1
#
# mixed workload (90/10)
# ./tools/bin/cassandra-stress user profile=/home/raphaelsc/scylla-tools-java/tools/my_cqlstress-example.yaml ops\(insert=5,simple1=5\) duration=30m -mode native cql3 -rate threads=100 -node 127.0.0.1


#
# Keyspace info
#
keyspace: metronome_staging

#
# The CQL for creating a keyspace (optional if it already exists)
#
keyspace_definition: |
  CREATE KEYSPACE metronome_staging WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 3};

#
# Table info
#
table: transaction_id_store

#
# The CQL for creating a table you wish to stress (optional if it already exists)
#
table_definition: |
    CREATE TABLE transaction_id_store (
        type tinyint,
        key blob,
        ts timestamp,
        value blob,
        PRIMARY KEY ((type, key))
    ) WITH bloom_filter_fp_chance = 0.01
        AND caching = {'keys': 'ALL', 'rows_per_partition': 'ALL'}
        AND comment = ''
        AND compaction = {'class': 'IncrementalCompactionStrategy', 'sstable_size_in_mb': '1000'}
        AND compression = {'sstable_compression': 'org.apache.cassandra.io.compress.LZ4Compressor'}
        AND crc_check_chance = 1.0
        AND dclocal_read_repair_chance = 0.0
        AND default_time_to_live = 3024000
        AND gc_grace_seconds = 3600
        AND max_index_interval = 2048
        AND memtable_flush_period_in_ms = 0
        AND min_index_interval = 128
        AND read_repair_chance = 0.0
        AND speculative_retry = '99.0PERCENTILE';
#    AND compression = { 'sstable_compression' : '' }
#    AND comment='A table of many types to test wide rows'

#
# Optional meta information on the generated columns in the above table
# The min and max only apply to text and blob types
# The distribution field represents the total unique population
# distribution of that column across rows.  Supported types are
# 
#      EXP(min..max)                        An exponential distribution over the range [min..max]
#      EXTREME(min..max,shape)              An extreme value (Weibull) distribution over the range [min..max]
#      GAUSSIAN(min..max,stdvrng)           A gaussian/normal distribution, where mean=(min+max)/2, and stdev is (mean-min)/stdvrng
#      GAUSSIAN(min..max,mean,stdev)        A gaussian/normal distribution, with explicitly defined mean and stdev
#      UNIFORM(min..max)                    A uniform distribution over the range [min, max]
#      FIXED(val)                           A fixed distribution, always returning the same value
#      SEQ(min..max)                        A fixed sequence, returning values in the range min to max sequentially (starting based on seed), wrapping if necessary.
#      Aliases: extr, gauss, normal, norm, weibull
#
#      If preceded by ~, the distribution is inverted
#
# Defaults for all columns are size: uniform(4..8), population: uniform(1..100B), cluster: fixed(1)
#
columnspec:
  - name: type
    size: uniform(1..10)
    population: fixed(2)
  - name: key
    size: fixed(87)
  - name: value
    size: fixed(4)

insert:
  partitions: fixed(1)             # number of unique partitions to update in a single operation
                                  # if batchcount > 1, multiple batches will be used but all partitions will
                                  # occur in all batches (unless they finish early); only the row counts will vary
  batchtype: LOGGED               # type of batch to use
  select: fixed(1)/1              # uniform chance any single generated CQL row will be visited in a partition;
                                  # generated for each partition independently, each time we visit it

#
# A list of queries you wish to run against the schema
#
queries:
   simple1:
      cql: select value from transaction_id_store where type = 2 and key = ? and ts >= ? ALLOW FILTERING;
      fields: samerow             # samerow or multirow (select arguments from the same row, or randomly from all rows in the partition)
